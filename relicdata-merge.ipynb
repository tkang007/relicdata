{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782acaeb-d738-4583-bbc2-1f6a2dca864d",
   "metadata": {},
   "source": [
    "# relic data, excel file merging notebook \n",
    "\n",
    "- 2024.12, tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cdde40a-7535-4fba-8461-116105a020cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.worksheet.worksheet import Worksheet\n",
    "from IPython.display import display\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8266c56-de86-4553-aa62-a01ded53666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7c902-d2c2-4a98-abf6-87e252dbb946",
   "metadata": {},
   "source": [
    "## Enviroments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5683e96f-3695-4ffe-8cab-d8ed689bbe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path - please update\n",
    "ifile1 = './data/전통문양 메타데이터 통합관리_v2.1.xlsx'\n",
    "ifile2 = './data/캡션검수_1125.xlsx'\n",
    "ofile1 = './data/master (20.전통문양).xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5752fb7-ec15-4c07-9bde-6e02ea7536c2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40de977-f842-4212-978d-c3488a66c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_suffix()->str:\n",
    "    return f'{os.getpid()}-{datetime.now().strftime(\"%H%M%S\")}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52509231-f94e-4d4f-82a2-b85d626b19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonempty_rows_count(sheet:Worksheet) -> int: \n",
    "    non_empty_rows = 0\n",
    "    for row in sheet.iter_rows():\n",
    "        if any(cell.value for cell in row):\n",
    "            non_empty_rows += 1\n",
    "    return non_empty_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c0b9bd-e699-4c01-8e23-9fe4fc1dccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workbook_info(workbook: Workbook, head:int=5, tail:int=5, datadisplay:bool=False) -> None:\n",
    "    \"\"\"print workbook and its sheet information\"\"\"\n",
    "    \n",
    "    # Get and print basic workbook properties\n",
    "    print(\"\\nWorkbook Properties:\")\n",
    "    #print(f\"Title: {workbook.properties.title}\")\n",
    "    #print(f\"Subject: {workbook.properties.subject}\")\n",
    "    #print(f\"Created: {workbook.properties.created}\")\n",
    "    print(f\"Modified: {workbook.properties.modified}\")\n",
    "    print(f\"Number of sheets: {len(workbook.sheetnames)}\")\n",
    "    print(f\"Names of sheets: {workbook.sheetnames}\")\n",
    "        \n",
    "    # Get sheet properties\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        sheet = workbook[sheet_name]\n",
    "        print(f\"\\nSheet: {sheet.title}\")\n",
    "        #print(f\"  Dimensions: {sheet.dimensions}\")  # Example: 'A1:C10'\n",
    "        print(f\"  Columns: {sheet.max_column}\")\n",
    "        print(f\"  Rows: {sheet.max_row}\")\n",
    "        print(f\"  Nonempty rows: {nonempty_rows_count(sheet)}\")\n",
    "\n",
    "\n",
    "        if datadisplay:\n",
    "            # Print a sample of the first 5 rows to understand content\n",
    "            if head:\n",
    "                print(f\"  First {head} rows:\")\n",
    "                for row in sheet.iter_rows(min_row=1, max_row=head, values_only=True):\n",
    "                    print(f\"    {row}\")        \n",
    "            if tail:\n",
    "                print(f\"  Tail {head} rows:\")\n",
    "                for row in sheet.iter_rows(min_row=sheet.max_row-tail, values_only=True):\n",
    "                    print(f\"    {row}\")                        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408a54d1-d67c-469d-bf28-a3279d110808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_rows_except_headers(sheet: Worksheet, header_row_count=1)->None:\n",
    "    # Find the number of rows in the sheet\n",
    "    total_rows = sheet.max_row\n",
    "    \n",
    "    # Loop through rows below the header and delete them\n",
    "    # for row_idx in range(total_rows, header_row_count, -1):  # Start from the bottom to avoid indexing issues\n",
    "    #     sheet.delete_rows(row_idx)\n",
    "    sheet.delete_rows(header_row_count+1, total_rows-header_row_count) \n",
    "    \n",
    "    print(f'sheet={sheet.title} truncate rows={total_rows-header_row_count} except header_row_count={header_row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58790b49-2163-4086-829c-a712ef28dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_and_width(sheet:Worksheet, max_width:int=28)->None:\n",
    "    # set as text and width min(width, maxwidth) \n",
    "\n",
    "    # Iterate over each column and set the text type and width\n",
    "    for column in sheet.columns:\n",
    "        column_letter = column[0].column_letter\n",
    "        sheet.column_dimensions[column_letter].number_format = '@'  # set text type \n",
    "        \n",
    "        max_length = max(len(str(cell.value)) for cell in column)\n",
    "        sheet.column_dimensions[column_letter].width = min(max_length + 2, max_width)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e60dc0-a51f-4859-8e5f-fe49476bbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_info(df:pd.DataFrame, head:int=5, tail:int=5, datadisplay:bool=False) -> None:\n",
    "    print(f'shape: {df.shape}')\n",
    "    print(f'columns:\\n{df.columns.tolist()}')\n",
    "    \n",
    "    if datadisplay:\n",
    "        if head:\n",
    "            print(f'head {head} rows:')\n",
    "            display(df.head(head))\n",
    "        if tail:\n",
    "            print(f'tail {tail} rows:')\n",
    "            display(df.tail(tail))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03b8aa-63b5-4654-8557-256f49b61dcc",
   "metadata": {},
   "source": [
    "## Excel file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb7426d3-6092-474e-b20e-dd8479faf055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workbook Properties:\n",
      "Modified: 2024-12-14 05:53:38.484267\n",
      "Number of sheets: 11\n",
      "Names of sheets: ['진행상황', '10.중앙박물관(HCI+)', '12.국가유산진흥원 발굴유물DB', '11.국가유산진흥원 직접촬영지원', '13.중앙박물관(LiST 1차)', '15.문화정보원(1차)', '14.중앙박물관(LiST 2차)', '17.문화정보원(2차)', '16.전통문화포털 2D문양', '원천유물명 검토', '시트11']\n",
      "\n",
      "Sheet: 진행상황\n",
      "  Columns: 23\n",
      "  Rows: 987\n",
      "  Nonempty rows: 35\n",
      "\n",
      "Sheet: 10.중앙박물관(HCI+)\n",
      "  Columns: 34\n",
      "  Rows: 6292\n",
      "  Nonempty rows: 6292\n",
      "\n",
      "Sheet: 12.국가유산진흥원 발굴유물DB\n",
      "  Columns: 32\n",
      "  Rows: 448\n",
      "  Nonempty rows: 448\n",
      "\n",
      "Sheet: 11.국가유산진흥원 직접촬영지원\n",
      "  Columns: 39\n",
      "  Rows: 2239\n",
      "  Nonempty rows: 2239\n",
      "\n",
      "Sheet: 13.중앙박물관(LiST 1차)\n",
      "  Columns: 32\n",
      "  Rows: 1590\n",
      "  Nonempty rows: 1590\n",
      "\n",
      "Sheet: 15.문화정보원(1차)\n",
      "  Columns: 36\n",
      "  Rows: 2687\n",
      "  Nonempty rows: 2687\n",
      "\n",
      "Sheet: 14.중앙박물관(LiST 2차)\n",
      "  Columns: 36\n",
      "  Rows: 13387\n",
      "  Nonempty rows: 13387\n",
      "\n",
      "Sheet: 17.문화정보원(2차)\n",
      "  Columns: 35\n",
      "  Rows: 6960\n",
      "  Nonempty rows: 6960\n",
      "\n",
      "Sheet: 16.전통문화포털 2D문양\n",
      "  Columns: 29\n",
      "  Rows: 999\n",
      "  Nonempty rows: 583\n",
      "\n",
      "Sheet: 원천유물명 검토\n",
      "  Columns: 12\n",
      "  Rows: 28950\n",
      "  Nonempty rows: 28950\n",
      "\n",
      "Sheet: 시트11\n",
      "  Columns: 1\n",
      "  Rows: 8660\n",
      "  Nonempty rows: 8660\n"
     ]
    }
   ],
   "source": [
    "# meta  file \n",
    "iwb1 = load_workbook(ifile1)\n",
    "#workbook_info(iwb1, head=3, tail=3, datadisplay=True)\n",
    "workbook_info(iwb1, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876b552a-a18b-4f7a-88dd-51e230dd02ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workbook Properties:\n",
      "Modified: 2024-12-14 05:53:58.941389\n",
      "Number of sheets: 15\n",
      "Names of sheets: ['캡션검수 1125', '캡션검수1126(수정)', '캡션검수1201', '캡션검수1202', '캡션검수1205', '캡션검수1206', '캡션검수1207(1,4문단)', '캡션검수1209(1,4문단)', '캡션검수1210(1,4문단)', '캡션검수1211(1,4문단)', '캡션검수1212(1,4문단)', '캡션검수1213(1문단,4문단)', '캡션검수1213-1(1문단,4문단)', '1214', '한글,한자 포함된 캡션']\n",
      "\n",
      "Sheet: 캡션검수 1125\n",
      "  Columns: 27\n",
      "  Rows: 1897\n",
      "  Nonempty rows: 1897\n",
      "\n",
      "Sheet: 캡션검수1126(수정)\n",
      "  Columns: 17\n",
      "  Rows: 3234\n",
      "  Nonempty rows: 3234\n",
      "\n",
      "Sheet: 캡션검수1201\n",
      "  Columns: 24\n",
      "  Rows: 1286\n",
      "  Nonempty rows: 1286\n",
      "\n",
      "Sheet: 캡션검수1202\n",
      "  Columns: 17\n",
      "  Rows: 1697\n",
      "  Nonempty rows: 1697\n",
      "\n",
      "Sheet: 캡션검수1205\n",
      "  Columns: 24\n",
      "  Rows: 1167\n",
      "  Nonempty rows: 1167\n",
      "\n",
      "Sheet: 캡션검수1206\n",
      "  Columns: 24\n",
      "  Rows: 2494\n",
      "  Nonempty rows: 2494\n",
      "\n",
      "Sheet: 캡션검수1207(1,4문단)\n",
      "  Columns: 24\n",
      "  Rows: 1542\n",
      "  Nonempty rows: 1542\n",
      "\n",
      "Sheet: 캡션검수1209(1,4문단)\n",
      "  Columns: 24\n",
      "  Rows: 1529\n",
      "  Nonempty rows: 1529\n",
      "\n",
      "Sheet: 캡션검수1210(1,4문단)\n",
      "  Columns: 24\n",
      "  Rows: 2351\n",
      "  Nonempty rows: 2351\n",
      "\n",
      "Sheet: 캡션검수1211(1,4문단)\n",
      "  Columns: 24\n",
      "  Rows: 1683\n",
      "  Nonempty rows: 1683\n",
      "\n",
      "Sheet: 캡션검수1212(1,4문단)\n",
      "  Columns: 24\n",
      "  Rows: 2031\n",
      "  Nonempty rows: 2031\n",
      "\n",
      "Sheet: 캡션검수1213(1문단,4문단)\n",
      "  Columns: 28\n",
      "  Rows: 1001\n",
      "  Nonempty rows: 883\n",
      "\n",
      "Sheet: 캡션검수1213-1(1문단,4문단)\n",
      "  Columns: 21\n",
      "  Rows: 4410\n",
      "  Nonempty rows: 4410\n",
      "\n",
      "Sheet: 1214\n",
      "  Columns: 21\n",
      "  Rows: 2943\n",
      "  Nonempty rows: 1943\n",
      "\n",
      "Sheet: 한글,한자 포함된 캡션\n",
      "  Columns: 1\n",
      "  Rows: 1000\n",
      "  Nonempty rows: 68\n"
     ]
    }
   ],
   "source": [
    "# caption file \n",
    "iwb2 = load_workbook(ifile2)\n",
    "workbook_info(iwb2, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9043361c-1ffe-4b2f-a3fa-216537c65f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workbook Properties:\n",
      "Modified: 2024-12-14 05:54:05.957158\n",
      "Number of sheets: 1\n",
      "Names of sheets: ['master']\n",
      "\n",
      "Sheet: master\n",
      "  Columns: 38\n",
      "  Rows: 27058\n",
      "  Nonempty rows: 27058\n"
     ]
    }
   ],
   "source": [
    "# master file \n",
    "owb1 = load_workbook(ofile1)\n",
    "workbook_info(owb1, datadisplay=False)\n",
    "# owb1 used later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff8241-95e9-42bf-b51f-6fa8609b0786",
   "metadata": {},
   "source": [
    "## Excel file read to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f0e81af-2cc8-470a-81be-b657110017d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta file\n",
    "\n",
    "meta_sheets_all = ['진행상황', '10.중앙박물관(HCI+)', '12.국가유산진흥원 발굴유물DB', '11.국가유산진흥원 직접촬영지원', '13.중앙박물관(LiST 1차)', '15.문화정보원(1차)', '14.중앙박물관(LiST 2차)', '17.문화정보원(2차)', '16.전통문화포털 2D문양', '원천유물명 검토', '시트11']  # 11\n",
    "meta_sheets_exclude =  ['진행상황', '16.전통문화포털 2D문양', '원천유물명 검토', '시트11']\n",
    "\n",
    "assert set(meta_sheets_all) == set(iwb1.sheetnames), 'meta_sheets_all is not mismatch with meta excell sheets'\n",
    "\n",
    "metacolumns = ['relic_id','relic_name','relic_common_name','pattern_usage','pattern_usage_detail','material','source','era','pattern_type','pattern_type_detail']  # 10\n",
    "\n",
    "metainfo = [\n",
    "    { 'sheet': '10.중앙박물관(HCI+)',\n",
    "      'skiprows': 4,\n",
    "      'usecols': [0,2,4,5,6,7,8,9,10,12],\n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '12.국가유산진흥원 발굴유물DB',\n",
    "      'skiprows': 5,\n",
    "      'usecols': [0,2,4,5,6,7,8,9,10,12],\n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '11.국가유산진흥원 직접촬영지원',\n",
    "      'skiprows': 5,\n",
    "      'usecols': [0,2,4,5,6,7,8,9,10,12],\n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '13.중앙박물관(LiST 1차)',\n",
    "      'skiprows': 5,\n",
    "      'usecols': [0,2,4,5,6,7,8,9,10,12],\n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '15.문화정보원(1차)',\n",
    "      'skiprows': 4,\n",
    "      'usecols': [0,2,5,6,7,8,9,10,11,13],\n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '14.중앙박물관(LiST 2차)',\n",
    "      'skiprows': 5,\n",
    "      'usecols': [0,2,4,5,6,7,8,9,10,12],\n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet':  '17.문화정보원(2차)',\n",
    "      'skiprows': 3,\n",
    "      'usecols': [0,2,4,5,6,7,8,9,10,12],\n",
    "      'dataframe': None,\n",
    "    },\n",
    "]    \n",
    "\n",
    "assert [sheet for sheet in meta_sheets_all if sheet not in meta_sheets_exclude] == [info['sheet'] for info in metainfo], \"metainfo sheet name or order not mismatch with valid sheets\"\n",
    "    \n",
    "for info in metainfo:\n",
    "    info['dataframe'] = pd.read_excel(ifile1, sheet_name=info['sheet'], skiprows=info['skiprows'], usecols=info['usecols'], header=None, names=metacolumns, na_filter=False, dtype='object', engine='openpyxl',)    \n",
    "    info['dataframe'].insert(0, 'sheet', info['sheet'])\n",
    "\n",
    "metadf = pd.concat([info['dataframe'] for info in metainfo])\n",
    "\n",
    "meta_all_rows = metadf.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7e04f1b-2d38-40f3-aa95-27ee71a0f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Strip whitespace from string columns\n",
    "string_cols = metadf.select_dtypes(include='object').columns\n",
    "metadf[string_cols] = metadf[string_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# remove invalid rows \n",
    "meta_invalid_df = metadf[(metadf['relic_id'].isnull()) | (metadf['relic_id'].str.len() < 1) | (metadf['relic_id'].str.contains(r\"\\s\"))]\n",
    "metadf = metadf[(metadf['relic_id'].notnull()) & (metadf['relic_id'].str.len() > 0) & (~metadf['relic_id'].str.contains(r\"\\s\"))]\n",
    "\n",
    "# remove duplicate rows \n",
    "meta_duplicate_df = metadf[metadf.duplicated(subset=['relic_id'], keep='last')]\n",
    "metadf = metadf.drop_duplicates(subset=['relic_id'], keep='last') \n",
    "\n",
    "meta_invalid_rows = meta_invalid_df.shape[0]\n",
    "meta_duplicate_rows = meta_duplicate_df.shape[0]\n",
    "meta_valid_rows = metadf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46025f7d-032c-477d-9eeb-ffa67dbb6874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta rows all=33572, valid=33563, invalid=2, duplicate=7\n"
     ]
    }
   ],
   "source": [
    "print(f'meta rows all={meta_all_rows}, valid={meta_valid_rows}, invalid={meta_invalid_rows}, duplicate={meta_duplicate_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b01822-08be-4f9e-8f5a-bcc10b18c58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (33563, 11)\n",
      "columns:\n",
      "['sheet', 'relic_id', 'relic_name', 'relic_common_name', 'pattern_usage', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_detail']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(metadf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69e4a912-dff2-495d-9158-e0c9ff880080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 11)\n",
      "columns:\n",
      "['sheet', 'relic_id', 'relic_name', 'relic_common_name', 'pattern_usage', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_detail']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(meta_invalid_df, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e317160-c3fe-4230-93aa-fac3a79fa5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 11)\n",
      "columns:\n",
      "['sheet', 'relic_id', 'relic_name', 'relic_common_name', 'pattern_usage', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_detail']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(meta_duplicate_df, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e55b68dc-0629-40ed-989b-47b2cb095e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug saving\n",
    "metadf.to_excel(f'./data/metabook-{filename_suffix()}.xlsx', index=False)\n",
    "if meta_invalid_rows:\n",
    "    meta_invalid_df.to_excel(f'./data/metabook-invalid-{filename_suffix()}.xlsx', index=False)\n",
    "if meta_duplicate_rows:    \n",
    "    meta_duplicate_df.to_excel(f'./data/metabook-duplicate-{filename_suffix()}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c696b86-c83e-469e-97ec-d59662e488dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caption file \n",
    "\n",
    "cap_sheets_all =  ['캡션검수 1125', '캡션검수1126(수정)', '캡션검수1201', '캡션검수1202', '캡션검수1205', '캡션검수1206', '캡션검수1207(1,4문단)', '캡션검수1209(1,4문단)', '캡션검수1210(1,4문단)', \n",
    "                 '캡션검수1211(1,4문단)', '캡션검수1212(1,4문단)', '캡션검수1213(1문단,4문단)', '캡션검수1213-1(1문단,4문단)', '1214', '한글,한자 포함된 캡션']  # 15\n",
    "cap_sheets_exclude = ['한글,한자 포함된 캡션']\n",
    "\n",
    "assert set(cap_sheets_all) == set(iwb2.sheetnames), 'cap_sheets_all is not mismatch with caption excell sheets'\n",
    "\n",
    "capcolumns = ['relic_id','1문단','2문단','3문단','4문단','5문단','6문단','1paragraph','2paragraph','3paragraph','4paragraph','5paragraph','6paragraph']  # 13\n",
    "cap_skiprows = 1\n",
    "cap_usecols = [0, 1,2,3,4,5,6, 11,12,13,14,15,16]\n",
    "\n",
    "capinfo = [\n",
    "    { 'sheet': '캡션검수 1125', \n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '캡션검수1126(수정)',\n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet':  '캡션검수1201', \n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '캡션검수1202', \n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '캡션검수1205', \n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '캡션검수1206',\n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet':  '캡션검수1207(1,4문단)', \n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '캡션검수1209(1,4문단)', \n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '캡션검수1210(1,4문단)', \n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },    \n",
    "    { 'sheet': '캡션검수1211(1,4문단)',\n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet':  '캡션검수1212(1,4문단)', \n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '캡션검수1213(1문단,4문단)',\n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet':  '캡션검수1213-1(1문단,4문단)', \n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "    { 'sheet': '1214',\n",
    "      'skiprows': cap_skiprows, \n",
    "      'usecols': cap_usecols, \n",
    "      'dataframe': None,\n",
    "    },\n",
    "]    \n",
    "\n",
    "assert [sheet for sheet in cap_sheets_all if sheet not in cap_sheets_exclude] == [info['sheet'] for info in capinfo], \"capinfo sheet name or order not mismatch with valid sheets\"\n",
    "\n",
    "for info in capinfo:\n",
    "    info['dataframe'] = pd.read_excel(ifile2, sheet_name=info['sheet'], skiprows=info['skiprows'], usecols=info['usecols'], header=None, names=capcolumns, na_filter=False, dtype='object', engine='openpyxl',)    \n",
    "    info['dataframe'].insert(0, 'sheet', info['sheet'])\n",
    "\n",
    "capdf = pd.concat([info['dataframe'] for info in capinfo])\n",
    "\n",
    "cap_all_rows = capdf.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb20dbee-20d4-459c-9ec7-a48d132882f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace from string columns\n",
    "string_cols = capdf.select_dtypes(include='object').columns\n",
    "capdf[string_cols] = capdf[string_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# remove invalid rows \n",
    "cap_invalid_df = capdf[(capdf['relic_id'].isnull()) | (capdf['relic_id'].str.len() < 1) | (capdf['relic_id'].str.contains(r\"\\s\"))]\n",
    "capdf = capdf[(capdf['relic_id'].notnull()) & (capdf['relic_id'].str.len() > 0) & (~capdf['relic_id'].str.contains(r\"\\s\"))]\n",
    "\n",
    "# remove duplicate rows \n",
    "cap_duplicate_df = capdf[capdf.duplicated(subset=['relic_id'], keep='last')]\n",
    "capdf = capdf.drop_duplicates(subset=['relic_id'], keep='last') \n",
    "\n",
    "cap_invalid_rows = cap_invalid_df.shape[0]\n",
    "cap_duplicate_rows = cap_duplicate_df.shape[0]\n",
    "cap_valid_rows = capdf.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9d9ad22-4ac7-4c38-9e4f-dc98ab87d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption rows all=28133, valid=23600, invalid=0, duplicate=4533\n"
     ]
    }
   ],
   "source": [
    "print(f'caption rows all={cap_all_rows}, valid={cap_valid_rows}, invalid={cap_invalid_rows}, duplicate={cap_duplicate_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f71a0c3-a841-4000-a750-468e2f1d432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (23600, 14)\n",
      "columns:\n",
      "['sheet', 'relic_id', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(capdf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a9fb109-e0a8-4a56-a240-07771abf9887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 14)\n",
      "columns:\n",
      "['sheet', 'relic_id', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(cap_invalid_df, datadisplay=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6513564d-6ab5-4996-90eb-c1ea593a3937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4533, 14)\n",
      "columns:\n",
      "['sheet', 'relic_id', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(cap_duplicate_df, datadisplay=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b6cbb3f-c798-4ea5-bd7d-28582ae93d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug saving\n",
    "capdf.to_excel(f'./data/capbook-{filename_suffix()}.xlsx', index=False)\n",
    "if cap_invalid_rows:\n",
    "    cap_invalid_df.to_excel(f'./data/capbook-invalid-{filename_suffix()}.xlsx', index=False)\n",
    "if cap_duplicate_rows:    \n",
    "    cap_duplicate_df.to_excel(f'./data/capbook-duplciate-{filename_suffix()}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca659cb4-d462-41e5-8305-d0b08b60d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master file \n",
    "\n",
    "# sheets_all =  ['master']\n",
    "\n",
    "master_heads = 4\n",
    "\n",
    "# columns_all:\n",
    "master_columns = [\n",
    "    'check','relic_id_img','relic_id','relic_name','relic_name_eng','relic_common_name','relic_common_name_eng','pattern_usage','pattern_usage_id','pattern_usage_detail','material','source','era','pattern_type','pattern_type_id','pattern_type_detail','pattern_type_detail_eng',\n",
    "    'relic_no','collect','photo_date','photo_eqipment','color','object_img_resolution','pattern_img_resolution','object_file_name','relic_symbol',\n",
    "    '1문단','2문단','3문단','4문단','5문단','6문단','1paragraph','2paragraph','3paragraph','4paragraph','5paragraph','6paragraph'\n",
    "]\n",
    "\n",
    "master_keep_names = [\n",
    "    'check','relic_id_img','relic_name_eng','relic_common_name_eng','pattern_usage_id','pattern_type_id','pattern_type_detail_eng','relic_no','collect','photo_date','photo_eqipment','color','object_img_resolution','pattern_img_resolution','object_file_name','relic_symbol'\n",
    "]\n",
    "\n",
    "master_keep_index = [master_columns.index(cn) for cn in master_keep_names] \n",
    "\n",
    "assert len(master_columns) == owb1['master'].max_column, 'master_columns count is not match with master excel sheet max_column'\n",
    "\n",
    "# check skiprows, usecols \n",
    "masdf = pd.read_excel(ofile1, sheet_name='master',  header=None,  skiprows=master_heads, usecols=master_keep_index, names=master_keep_names, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "masdf.insert(0,'sheet','master')\n",
    "\n",
    "mas_all_rows = masdf.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf9b8d36-812b-4f4d-ba31-dafbdaec9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace from string columns\n",
    "string_cols = masdf.select_dtypes(include='object').columns\n",
    "masdf[string_cols] = masdf[string_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# remove invalid rows \n",
    "mas_invalid_df = masdf[(masdf['relic_id_img'].isnull()) | (masdf['relic_id_img'].str.len() < 1) | (masdf['relic_id_img'].str.contains(r\"\\s\"))]\n",
    "masdf = masdf[(masdf['relic_id_img'].notnull()) & (masdf['relic_id_img'].str.len() > 0) & (~masdf['relic_id_img'].str.contains(r\"\\s\"))]\n",
    "\n",
    "# remove duplicate rows \n",
    "mas_duplicate_df = masdf[masdf.duplicated(subset=['relic_id_img'], keep='last')]\n",
    "masdf = masdf.drop_duplicates(subset=['relic_id_img'], keep='last') \n",
    "\n",
    "mas_invalid_rows = mas_invalid_df.shape[0]\n",
    "mas_duplicate_rows = mas_duplicate_df.shape[0]\n",
    "mas_valid_rows = masdf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56a64ab0-f20e-492a-a586-dd767505e585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master rows all=27054, valid=27052, invalid=2, duplicate=0\n"
     ]
    }
   ],
   "source": [
    "print(f'master rows all={mas_all_rows}, valid={mas_valid_rows}, invalid={mas_invalid_rows}, duplicate={mas_duplicate_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f9f53d4-4fe3-4d16-8ca2-cca06b86d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (27052, 17)\n",
      "columns:\n",
      "['sheet', 'check', 'relic_id_img', 'relic_name_eng', 'relic_common_name_eng', 'pattern_usage_id', 'pattern_type_id', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(masdf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68098858-5de7-4d75-8f53-0893b1528d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 17)\n",
      "columns:\n",
      "['sheet', 'check', 'relic_id_img', 'relic_name_eng', 'relic_common_name_eng', 'pattern_usage_id', 'pattern_type_id', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(mas_invalid_df, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2316b4e-9823-4a46-85e9-ce1c2dd4c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 17)\n",
      "columns:\n",
      "['sheet', 'check', 'relic_id_img', 'relic_name_eng', 'relic_common_name_eng', 'pattern_usage_id', 'pattern_type_id', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(mas_duplicate_df, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dff5c51-f647-4d60-b010-bfee6b706ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug saving\n",
    "masdf.to_excel(f'./data/masbook-{filename_suffix()}.xlsx', index=False)\n",
    "if mas_invalid_rows:\n",
    "    mas_invalid_df.to_excel(f'./data/masbook-invalid-{filename_suffix()}.xlsx', index=False)\n",
    "if mas_duplicate_rows:    \n",
    "    mas_duplicate_df.to_excel(f'./data/masbook-duplicate-{filename_suffix()}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19300831-4308-4564-b570-12db436aed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete sheet column before merge\n",
    "metadf.drop('sheet', axis=1, inplace=True)\n",
    "capdf.drop('sheet', axis=1, inplace=True)\n",
    "masdf.drop('sheet', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9afd5-27db-494e-aada-c8433c72f120",
   "metadata": {},
   "source": [
    "## Merge master, meta and caption dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8a3d722-fc20-42b5-a275-bb2b9d7217b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join masdf, metadf, capdf \n",
    "\n",
    "# Find values in masdf['relic_id'] that not metadf['relic_id'] \n",
    "meta_notfound_values = masdf['relic_id_img'][~masdf['relic_id_img'].isin(metadf['relic_id'])]\n",
    "meta_notfound_rows = meta_notfound_values.count()\n",
    "\n",
    "# Find values in masdf['relic_id'] that not metadf['relic_id'] \n",
    "cap_notfound_values = masdf['relic_id_img'][~masdf['relic_id_img'].isin(capdf['relic_id'])]\n",
    "cap_notfound_rows = cap_notfound_values.count()\n",
    "\n",
    "# inner join\n",
    "innerdf = masdf.merge(metadf, how='inner', left_on='relic_id_img', right_on='relic_id', suffixes=['_left1','_right1'], copy=True)  # relic_id added\n",
    "innerdf = innerdf.merge(capdf, how='inner', left_on='relic_id_img', right_on='relic_id', suffixes=['_left2','_right2'], copy=True) # relic_id_left2, relic_id_right2  \n",
    "mas_inner_rows = innerdf.shape[0]\n",
    "\n",
    "# left outer join\n",
    "outerdf = masdf.merge(metadf, how='left', left_on='relic_id_img', right_on='relic_id', suffixes=['_left1','_right1'], copy=True)  # relic_id added\n",
    "outerdf = outerdf.merge(capdf, how='left', left_on='relic_id_img', right_on='relic_id', suffixes=['_left2','_right2'], copy=True) # relic_id_left2, relic_id_right2  \n",
    "mas_outer_rows = outerdf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c76cb22e-a803-4487-86f7-f4dcc2586412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['check', 'relic_id_img', 'relic_name_eng', 'relic_common_name_eng', 'pattern_usage_id', 'pattern_type_id', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol', 'relic_id_left2', 'relic_name', 'relic_common_name', 'pattern_usage', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_detail', 'relic_id_right2', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n",
      "['check', 'relic_id_img', 'relic_id', 'relic_name', 'relic_name_eng', 'relic_common_name', 'relic_common_name_eng', 'pattern_usage', 'pattern_usage_id', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_id', 'pattern_type_detail', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "# delete relic_id_left2, relic_id_right2\n",
    "print(innerdf.columns.tolist())\n",
    "innerdf = innerdf.drop([ 'relic_id_left2','relic_id_right2'], axis=1)\n",
    "# assign relic_id with relic_id_img \n",
    "innerdf['relic_id'] = innerdf['relic_id_img']\n",
    "# reorder columns\n",
    "innerdf = innerdf[master_columns]\n",
    "print(innerdf.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d1cc003-9768-4ca1-b254-eb74834f60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outerdf = outerdf.drop(['relic_id_left2','relic_id_right2'],axis=1)\n",
    "outerdf['relic_id'] = outerdf['relic_id_img']\n",
    "outerdf = outerdf[master_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "414b8435-1f40-4e50-b2da-c90088103a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master inner join rows=21592, outer join rows=27052, meta notfound=126, caption notfound=5457\n"
     ]
    }
   ],
   "source": [
    "print(f'master inner join rows={mas_inner_rows}, outer join rows={mas_outer_rows}, meta notfound={meta_notfound_rows}, caption notfound={cap_notfound_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fbd5229-3aa5-40c2-974c-42cbfffefce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relic_id_img not found at meta\n",
      "count: 126\n",
      "values:\n",
      "2744     PS0100101200100217800000_A1\n",
      "3303     PS0100101410100566900000_A1\n",
      "3410     PS0100101410101060900000_A1\n",
      "10462                       21248_A1\n",
      "10463                       21249_A1\n",
      "                    ...             \n",
      "26593    PS0100100800100882600000_A3\n",
      "26595    PS0100100800100883000000_A2\n",
      "26596    PS0100100800100883000000_A3\n",
      "26598    PS0100100800100889300000_A2\n",
      "26599    PS0100100800100889300000_A3\n",
      "Name: relic_id_img, Length: 126, dtype: object\n"
     ]
    }
   ],
   "source": [
    "if meta_notfound_rows:\n",
    "    print('relic_id_img not found at meta')\n",
    "    print(f'count: {meta_notfound_rows}') \n",
    "    print(f'values:\\n{meta_notfound_values}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1256af53-e04d-4fcd-91a5-25f2655102db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relic_id_img not found at caption\n",
      "count: 5457\n",
      "values:\n",
      "7        PS0100200100103812700000_A1\n",
      "212      PS0100200100104029800000_A1\n",
      "1062     PS0100300500100105000000_A1\n",
      "1063     PS0100300500100106300000_A1\n",
      "1066     PS0100300500100111600000_A2\n",
      "                    ...             \n",
      "27040    PS0100100900100528000000_A2\n",
      "27041    PS0100100900100528000000_A3\n",
      "27045    PS0100308700200174400000_A1\n",
      "27047    PS0100308700200174400000_A3\n",
      "27050    PS0100308700200317400000_A3\n",
      "Name: relic_id_img, Length: 5457, dtype: object\n"
     ]
    }
   ],
   "source": [
    "if cap_notfound_rows:\n",
    "    print('relic_id_img not found at caption')\n",
    "    print(f'count: {cap_notfound_rows}') \n",
    "    print(f'values:\\n{cap_notfound_values}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2966f7e1-4aa2-4622-bc8c-c73277020934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (21592, 38)\n",
      "columns:\n",
      "['check', 'relic_id_img', 'relic_id', 'relic_name', 'relic_name_eng', 'relic_common_name', 'relic_common_name_eng', 'pattern_usage', 'pattern_usage_id', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_id', 'pattern_type_detail', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(innerdf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efec9e6f-147b-4fd7-9264-ac149764dd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (27052, 38)\n",
      "columns:\n",
      "['check', 'relic_id_img', 'relic_id', 'relic_name', 'relic_name_eng', 'relic_common_name', 'relic_common_name_eng', 'pattern_usage', 'pattern_usage_id', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_id', 'pattern_type_detail', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(outerdf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "010d845c-7432-4d34-9f26-138c90ee3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debuging\n",
    "if meta_notfound_rows:\n",
    "    with open(f'./data/master-notfound-meta-{filename_suffix()}.txt', 'w') as file:\n",
    "         pprint(meta_notfound_values.tolist(), stream=file)\n",
    "if cap_notfound_rows:\n",
    "    with open(f'./data/master-notfound-caption-{filename_suffix()}.txt', 'w') as file:\n",
    "        pprint(cap_notfound_values.tolist(), stream=file)\n",
    "                \n",
    "innerdf.to_excel(f'./data/innerbook-{filename_suffix()}.xlsx', index=False)\n",
    "outerdf.to_excel(f'./data/outerbook-{filename_suffix()}.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eadbd6-4a5f-4438-8044-d0e01e5ec46b",
   "metadata": {},
   "source": [
    "## Write to master workbook with outerdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69e7f802-4bbc-4926-9f1e-5cfd752223ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheet=master truncate rows=27054 except header_row_count=4\n"
     ]
    }
   ],
   "source": [
    "# prepare master sheet with header only, trucate datarows \n",
    "masheet = owb1['master']\n",
    "\n",
    "# trucate data\n",
    "truncate_rows_except_headers(masheet, header_row_count=master_heads)\n",
    "\n",
    "# fill master sheet with outerdf \n",
    "for row in outerdf.itertuples(index=False): \n",
    "    masheet.append(row)\n",
    "\n",
    "# set text type and max width \n",
    "text_and_width(masheet, max_width=28) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e64aad6-ecfb-4e5a-b601-7a636478cbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workbook Properties:\n",
      "Modified: 2024-12-14 05:54:05.957158\n",
      "Number of sheets: 1\n",
      "Names of sheets: ['master']\n",
      "\n",
      "Sheet: master\n",
      "  Columns: 38\n",
      "  Rows: 27056\n",
      "  Nonempty rows: 27056\n"
     ]
    }
   ],
   "source": [
    "workbook_info(owb1, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d95f9a64-e7c7-4819-a51f-9a75a3ae4185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result file=./data/master-6560-150016.xlsx\n"
     ]
    }
   ],
   "source": [
    "# master saving\n",
    "filename = f'./data/master-{filename_suffix()}.xlsx'\n",
    "owb1.save(filename) \n",
    "print(f'result file={filename}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fe38f94-66ac-42bc-84f3-c65eae4e74ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, eplapsed seconds = 410.0350081920624\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Done, eplapsed seconds = {end_time - start_time}\")\n",
    "\n",
    "# copy file to \\\\BlueServer\\임시폴더\\강태원임시파일\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e548c-591b-4e23-ac12-1310fa639552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
