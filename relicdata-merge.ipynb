{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782acaeb-d738-4583-bbc2-1f6a2dca864d",
   "metadata": {},
   "source": [
    "# relic data, excel file merging notebook \n",
    "\n",
    "- 2024.12, tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cdde40a-7535-4fba-8461-116105a020cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.worksheet.worksheet import Worksheet\n",
    "from IPython.display import display\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8266c56-de86-4553-aa62-a01ded53666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7c902-d2c2-4a98-abf6-87e252dbb946",
   "metadata": {},
   "source": [
    "## Enviroments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5683e96f-3695-4ffe-8cab-d8ed689bbe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path - please update\n",
    "ifile1 = './data/전통문양 메타데이터 통합관리_v2.1.xlsx'\n",
    "ifile2 = './data/캡션검수_1125.xlsx'\n",
    "ofile1 = './data/master (20.전통문양).xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5752fb7-ec15-4c07-9bde-6e02ea7536c2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40de977-f842-4212-978d-c3488a66c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_suffix()->str:\n",
    "    return f'{os.getpid()}-{datetime.now().strftime(\"%H%M%S\")}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52509231-f94e-4d4f-82a2-b85d626b19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonempty_rows_count(sheet:Worksheet) -> int: \n",
    "    non_empty_rows = 0\n",
    "    for row in sheet.iter_rows():\n",
    "        if any(cell.value for cell in row):\n",
    "            non_empty_rows += 1\n",
    "    return non_empty_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c0b9bd-e699-4c01-8e23-9fe4fc1dccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workbook_info(workbook: Workbook, head:int=5, tail:int=5, datadisplay:bool=False) -> None:\n",
    "    \"\"\"print workbook and its sheet information\"\"\"\n",
    "    \n",
    "    # Get and print basic workbook properties\n",
    "    print(\"\\nWorkbook Properties:\")\n",
    "    #print(f\"Title: {workbook.properties.title}\")\n",
    "    #print(f\"Subject: {workbook.properties.subject}\")\n",
    "    #print(f\"Created: {workbook.properties.created}\")\n",
    "    print(f\"Modified: {workbook.properties.modified}\")\n",
    "    print(f\"Number of sheets: {len(workbook.sheetnames)}\")\n",
    "    print(f\"Names of sheets: {workbook.sheetnames}\")\n",
    "        \n",
    "    # Get sheet properties\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        sheet = workbook[sheet_name]\n",
    "        print(f\"\\nSheet: {sheet.title}\")\n",
    "        #print(f\"  Dimensions: {sheet.dimensions}\")  # Example: 'A1:C10'\n",
    "        print(f\"  Columns: {sheet.max_column}\")\n",
    "        print(f\"  Rows: {sheet.max_row}\")\n",
    "        print(f\"  Nonempty rows: {nonempty_rows_count(sheet)}\")\n",
    "\n",
    "\n",
    "        if datadisplay:\n",
    "            # Print a sample of the first 5 rows to understand content\n",
    "            if head:\n",
    "                print(f\"  First {head} rows:\")\n",
    "                for row in sheet.iter_rows(min_row=1, max_row=head, values_only=True):\n",
    "                    print(f\"    {row}\")        \n",
    "            if tail:\n",
    "                print(f\"  Tail {head} rows:\")\n",
    "                for row in sheet.iter_rows(min_row=sheet.max_row-tail, values_only=True):\n",
    "                    print(f\"    {row}\")                        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408a54d1-d67c-469d-bf28-a3279d110808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_rows_except_headers(sheet: Worksheet, header_row_count=1)->None:\n",
    "    # Find the number of rows in the sheet\n",
    "    total_rows = sheet.max_row\n",
    "    \n",
    "    # Loop through rows below the header and delete them\n",
    "    # for row_idx in range(total_rows, header_row_count, -1):  # Start from the bottom to avoid indexing issues\n",
    "    #     sheet.delete_rows(row_idx)\n",
    "    sheet.delete_rows(header_row_count+1, total_rows-header_row_count) \n",
    "    \n",
    "    print(f'sheet={sheet.title} truncate rows={total_rows-header_row_count} except header_row_count={header_row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58790b49-2163-4086-829c-a712ef28dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_and_width(sheet:Worksheet, max_width:int=28)->None:\n",
    "    # set as text and width min(width, maxwidth) \n",
    "\n",
    "    # Iterate over each column and set the text type and width\n",
    "    for column in sheet.columns:\n",
    "        column_letter = column[0].column_letter\n",
    "        sheet.column_dimensions[column_letter].number_format = '@'  # set text type \n",
    "        \n",
    "        max_length = max(len(str(cell.value)) for cell in column)\n",
    "        sheet.column_dimensions[column_letter].width = min(max_length + 2, max_width)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e60dc0-a51f-4859-8e5f-fe49476bbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_info(df:pd.DataFrame, head:int=5, tail:int=5, datadisplay:bool=False) -> None:\n",
    "    print(f'shape: {df.shape}')\n",
    "    print(f'columns:\\n{df.columns.tolist()}')\n",
    "    \n",
    "    if datadisplay:\n",
    "        if head:\n",
    "            print(f'head {head} rows:')\n",
    "            display(df.head(head))\n",
    "        if tail:\n",
    "            print(f'tail {tail} rows:')\n",
    "            display(df.tail(tail))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03b8aa-63b5-4654-8557-256f49b61dcc",
   "metadata": {},
   "source": [
    "## Excel file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb7426d3-6092-474e-b20e-dd8479faf055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workbook Properties:\n",
      "Modified: 2024-12-13 07:29:04.918547\n",
      "Number of sheets: 11\n",
      "Names of sheets: ['진행상황', '10.중앙박물관(HCI+)', '12.국가유산진흥원 발굴유물DB', '11.국가유산진흥원 직접촬영지원', '13.중앙박물관(LiST 1차)', '15.문화정보원(1차)', '14.중앙박물관(LiST 2차)', '17.문화정보원(2차)', '16.전통문화포털 2D문양', '원천유물명 검토', '시트11']\n",
      "\n",
      "Sheet: 진행상황\n",
      "  Columns: 23\n",
      "  Rows: 987\n",
      "  Nonempty rows: 35\n",
      "\n",
      "Sheet: 10.중앙박물관(HCI+)\n",
      "  Columns: 34\n",
      "  Rows: 6292\n",
      "  Nonempty rows: 6292\n",
      "\n",
      "Sheet: 12.국가유산진흥원 발굴유물DB\n",
      "  Columns: 32\n",
      "  Rows: 448\n",
      "  Nonempty rows: 448\n",
      "\n",
      "Sheet: 11.국가유산진흥원 직접촬영지원\n",
      "  Columns: 39\n",
      "  Rows: 2239\n",
      "  Nonempty rows: 2239\n",
      "\n",
      "Sheet: 13.중앙박물관(LiST 1차)\n",
      "  Columns: 32\n",
      "  Rows: 1590\n",
      "  Nonempty rows: 1590\n",
      "\n",
      "Sheet: 15.문화정보원(1차)\n",
      "  Columns: 36\n",
      "  Rows: 2687\n",
      "  Nonempty rows: 2687\n",
      "\n",
      "Sheet: 14.중앙박물관(LiST 2차)\n",
      "  Columns: 36\n",
      "  Rows: 13387\n",
      "  Nonempty rows: 13387\n",
      "\n",
      "Sheet: 17.문화정보원(2차)\n",
      "  Columns: 35\n",
      "  Rows: 6960\n",
      "  Nonempty rows: 6960\n",
      "\n",
      "Sheet: 16.전통문화포털 2D문양\n",
      "  Columns: 29\n",
      "  Rows: 999\n",
      "  Nonempty rows: 583\n",
      "\n",
      "Sheet: 원천유물명 검토\n",
      "  Columns: 12\n",
      "  Rows: 28950\n",
      "  Nonempty rows: 28950\n",
      "\n",
      "Sheet: 시트11\n",
      "  Columns: 1\n",
      "  Rows: 8660\n",
      "  Nonempty rows: 8660\n"
     ]
    }
   ],
   "source": [
    "# meta  file \n",
    "iwb1 = load_workbook(ifile1)\n",
    "#workbook_info(iwb1, head=3, tail=3, datadisplay=True)\n",
    "workbook_info(iwb1, datadisplay=False)\n",
    "iwb1 = None # release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876b552a-a18b-4f7a-88dd-51e230dd02ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workbook Properties:\n",
      "Modified: 2024-12-13 07:29:26.223184\n",
      "Number of sheets: 14\n",
      "Names of sheets: ['캡션검수 1125', '캡션검수1126(수정)', '캡션검수1201', '캡션검수1202', '캡션검수1205', '캡션검수1206', '캡션검수1207(1,4문단)', '캡션검수1209(1,4문단)', '캡션검수1210(1,4문단)', '캡션검수1211(1,4문단)', '캡션검수1212(1,4문단)', '캡션검수1213(1문단,4문단)', '캡션검수1213-2', '한글,한자 포함된 캡션']\n",
      "\n",
      "Sheet: 캡션검수 1125\n",
      "  Columns: 34\n",
      "  Rows: 1898\n",
      "  Nonempty rows: 1898\n",
      "\n",
      "Sheet: 캡션검수1126(수정)\n",
      "  Columns: 24\n",
      "  Rows: 3235\n",
      "  Nonempty rows: 3235\n",
      "\n",
      "Sheet: 캡션검수1201\n",
      "  Columns: 30\n",
      "  Rows: 1286\n",
      "  Nonempty rows: 1286\n",
      "\n",
      "Sheet: 캡션검수1202\n",
      "  Columns: 23\n",
      "  Rows: 1697\n",
      "  Nonempty rows: 1697\n",
      "\n",
      "Sheet: 캡션검수1205\n",
      "  Columns: 30\n",
      "  Rows: 1167\n",
      "  Nonempty rows: 1167\n",
      "\n",
      "Sheet: 캡션검수1206\n",
      "  Columns: 30\n",
      "  Rows: 2494\n",
      "  Nonempty rows: 2494\n",
      "\n",
      "Sheet: 캡션검수1207(1,4문단)\n",
      "  Columns: 30\n",
      "  Rows: 1542\n",
      "  Nonempty rows: 1542\n",
      "\n",
      "Sheet: 캡션검수1209(1,4문단)\n",
      "  Columns: 30\n",
      "  Rows: 1529\n",
      "  Nonempty rows: 1529\n",
      "\n",
      "Sheet: 캡션검수1210(1,4문단)\n",
      "  Columns: 30\n",
      "  Rows: 2561\n",
      "  Nonempty rows: 2351\n",
      "\n",
      "Sheet: 캡션검수1211(1,4문단)\n",
      "  Columns: 30\n",
      "  Rows: 1683\n",
      "  Nonempty rows: 1683\n",
      "\n",
      "Sheet: 캡션검수1212(1,4문단)\n",
      "  Columns: 30\n",
      "  Rows: 2031\n",
      "  Nonempty rows: 2031\n",
      "\n",
      "Sheet: 캡션검수1213(1문단,4문단)\n",
      "  Columns: 34\n",
      "  Rows: 1001\n",
      "  Nonempty rows: 883\n",
      "\n",
      "Sheet: 캡션검수1213-2\n",
      "  Columns: 30\n",
      "  Rows: 1570\n",
      "  Nonempty rows: 1570\n",
      "\n",
      "Sheet: 한글,한자 포함된 캡션\n",
      "  Columns: 1\n",
      "  Rows: 1000\n",
      "  Nonempty rows: 68\n"
     ]
    }
   ],
   "source": [
    "# caption file \n",
    "iwb2 = load_workbook(ifile2)\n",
    "workbook_info(iwb2, datadisplay=False)\n",
    "iwb2 = None # release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9043361c-1ffe-4b2f-a3fa-216537c65f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workbook Properties:\n",
      "Modified: 2024-12-13 07:29:36.679685\n",
      "Number of sheets: 1\n",
      "Names of sheets: ['master']\n",
      "\n",
      "Sheet: master\n",
      "  Columns: 38\n",
      "  Rows: 27058\n",
      "  Nonempty rows: 27058\n"
     ]
    }
   ],
   "source": [
    "# master file \n",
    "owb1 = load_workbook(ofile1)\n",
    "workbook_info(owb1, datadisplay=False)\n",
    "# owb1 used later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff8241-95e9-42bf-b51f-6fa8609b0786",
   "metadata": {},
   "source": [
    "## Excel file read to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f0e81af-2cc8-470a-81be-b657110017d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta file\n",
    "\n",
    "# sheets_all: ['진행상황', '10.중앙박물관(HCI+)', '12.국가유산진흥원 발굴유물DB', '11.국가유산진흥원 직접촬영지원', '13.중앙박물관(LiST 1차)', '15.문화정보원(1차)', '14.중앙박물관(LiST 2차)', '17.문화정보원(2차)', '16.전통문화포털 2D문양', '원천유물명 검토', '시트11']\n",
    "# sheets_excluded =  ['진행상황', '16.전통문화포털 2D문양', '원천유물명 검토', '시트11']\n",
    "\n",
    "metadfs = {}\n",
    "columns = ['relic_id','relic_name','relic_common_name','pattern_usage','pattern_usage_detail','material','source','era','pattern_type','pattern_type_detail']  # 10\n",
    "\n",
    "# check skiprows and usecols per sheet\n",
    "metadfs['meta10'] = pd.read_excel(ifile1, sheet_name='10.중앙박물관(HCI+)',           skiprows=4, usecols=[0,2,4,5,6,7,8,9,10,12],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)  # all column data type as string\n",
    "metadfs['meta11'] = pd.read_excel(ifile1, sheet_name='11.국가유산진흥원 직접촬영지원', skiprows=5, usecols=[0,2,4,5,6,7,8,9,10,12],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "metadfs['meta12'] = pd.read_excel(ifile1, sheet_name='12.국가유산진흥원 발굴유물DB',   skiprows=5, usecols=[0,2,4,5,6,7,8,9,10,12],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "metadfs['meta13'] = pd.read_excel(ifile1, sheet_name='13.중앙박물관(LiST 1차)',       skiprows=5, usecols=[0,2,4,5,6,7,8,9,10,12],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "metadfs['meta14'] = pd.read_excel(ifile1, sheet_name='14.중앙박물관(LiST 2차)',       skiprows=5, usecols=[0,2,4,5,6,7,8,9,10,12],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)    \n",
    "metadfs['meta15'] = pd.read_excel(ifile1, sheet_name='15.문화정보원(1차)',            skiprows=4, usecols=[0,2,5,6,7,8,9,10,11,13], header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)    \n",
    "metadfs['meta17'] = pd.read_excel(ifile1, sheet_name='17.문화정보원(2차)',            skiprows=3, usecols=[0,2,4,5,6,7,8,9,10,12],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)    \n",
    "\n",
    "metadf = pd.concat([val for key,val in metadfs.items()])\n",
    "\n",
    "meta_all_rows = metadf.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7e04f1b-2d38-40f3-aa95-27ee71a0f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Strip whitespace from string columns\n",
    "string_cols = metadf.select_dtypes(include='object').columns\n",
    "metadf[string_cols] = metadf[string_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# remove invalid rows \n",
    "meta_invalid_df = metadf[(metadf['relic_id'].isnull()) | (metadf['relic_id'].str.len() < 1)]\n",
    "metadf = metadf[(metadf['relic_id'].notnull()) & (metadf['relic_id'].str.len() > 0)]\n",
    "\n",
    "# remove duplicate rows \n",
    "meta_duplicate_df = metadf[metadf.duplicated(subset=['relic_id'])]\n",
    "metadf = metadf.drop_duplicates(subset=['relic_id']) \n",
    "\n",
    "meta_invalid_rows = meta_invalid_df.shape[0]\n",
    "meta_duplicate_rows = meta_duplicate_df.shape[0]\n",
    "meta_valid_rows = metadf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46025f7d-032c-477d-9eeb-ffa67dbb6874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta rows all=33572, valid=33563, invalid=2, duplicate=7\n"
     ]
    }
   ],
   "source": [
    "print(f'meta rows all={meta_all_rows}, valid={meta_valid_rows}, invalid={meta_invalid_rows}, duplicate={meta_duplicate_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b01822-08be-4f9e-8f5a-bcc10b18c58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (33563, 10)\n",
      "columns:\n",
      "['relic_id', 'relic_name', 'relic_common_name', 'pattern_usage', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_detail']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(metadf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69e4a912-dff2-495d-9158-e0c9ff880080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 10)\n",
      "columns:\n",
      "['relic_id', 'relic_name', 'relic_common_name', 'pattern_usage', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_detail']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(meta_invalid_df, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e317160-c3fe-4230-93aa-fac3a79fa5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 10)\n",
      "columns:\n",
      "['relic_id', 'relic_name', 'relic_common_name', 'pattern_usage', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_detail']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(meta_invalid_df, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e55b68dc-0629-40ed-989b-47b2cb095e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug saving\n",
    "metadf.to_excel(f'./data/metabook-{filename_suffix()}.xlsx', index=False)\n",
    "if meta_invalid_rows:\n",
    "    meta_invalid_df.to_excel(f'./data/metabook-invalid-{filename_suffix()}.xlsx', index=False)\n",
    "if meta_duplicate_rows:    \n",
    "    meta_duplicate_df.to_excel(f'./data/metabook-duplicate-{filename_suffix()}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c696b86-c83e-469e-97ec-d59662e488dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caption file \n",
    "\n",
    "# sheets_all =  ['캡션검수 1125', '캡션검수1126(수정)', '캡션검수1201', '캡션검수1202', '캡션검수1205', '캡션검수1206', '캡션검수1207(1,4문단)', '캡션검수1209(1,4문단)', '캡션검수1210(1,4문단)']\n",
    "# sheets_exclude = []\n",
    "\n",
    "capdfs = {}\n",
    "columns = ['relic_id','1문단','2문단','3문단','4문단','5문단','6문단','1paragraph','2paragraph','3paragraph','4paragraph','5paragraph','6paragraph']  # 13\n",
    "\n",
    "# check skiprows, usecols \n",
    "capdfs['cap1125']  = pd.read_excel(ifile2, sheet_name='캡션검수 1125',           skiprows=2, usecols=[1, 8,9,10,11,12,13,  18,19,20,21,22,23],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "capdfs['cap1126a'] = pd.read_excel(ifile2, sheet_name='캡션검수1126(수정)',      skiprows=1, usecols=[1, 8,9,10,11,12,13,  18,19,20,21,22,23],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "\n",
    "capdfs['cap1201']  = pd.read_excel(ifile2, sheet_name='캡션검수1201',            skiprows=1, usecols=[0, 7,8,9,10,11,12,  17,18,19,20,21,22],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "capdfs['cap1202']  = pd.read_excel(ifile2, sheet_name='캡션검수1202',            skiprows=1, usecols=[0, 7,8,9,10,11,12,  17,18,19,20,21,22],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "capdfs['cap1205']  = pd.read_excel(ifile2, sheet_name='캡션검수1205',            skiprows=1, usecols=[0, 7,8,9,10,11,12,  17,18,19,20,21,22],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "capdfs['cap1206']  = pd.read_excel(ifile2, sheet_name='캡션검수1206',            skiprows=1, usecols=[0, 7,8,9,10,11,12,  17,18,19,20,21,22],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "capdfs['cap1207']  = pd.read_excel(ifile2, sheet_name='캡션검수1207(1,4문단)',   skiprows=1, usecols=[0, 7,8,9,10,11,12,  17,18,19,20,21,22],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "capdfs['cap1209']  = pd.read_excel(ifile2, sheet_name='캡션검수1209(1,4문단)',   skiprows=1, usecols=[0, 7,8,9,10,11,12,  17,18,19,20,21,22],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "capdfs['cap1210']  = pd.read_excel(ifile2, sheet_name='캡션검수1210(1,4문단)',   skiprows=1, usecols=[0, 7,8,9,10,11,12,  17,18,19,20,21,22],  header=None, names=columns, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "\n",
    "capdf = pd.concat([val for key,val in capdfs.items()])\n",
    "\n",
    "cap_all_rows = capdf.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb20dbee-20d4-459c-9ec7-a48d132882f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace from string columns\n",
    "string_cols = capdf.select_dtypes(include='object').columns\n",
    "capdf[string_cols] = capdf[string_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# remove invalid rows \n",
    "cap_invalid_df = capdf[(capdf['relic_id'].isnull()) | (capdf['relic_id'].str.len() < 1)]\n",
    "capdf = capdf[(capdf['relic_id'].notnull()) & (capdf['relic_id'].str.len() > 0)]\n",
    "\n",
    "# remove duplicate rows \n",
    "cap_duplicate_df = capdf[capdf.duplicated(subset=['relic_id'])]\n",
    "capdf = capdf.drop_duplicates(subset=['relic_id']) \n",
    "\n",
    "cap_invalid_rows = cap_invalid_df.shape[0]\n",
    "cap_duplicate_rows = cap_duplicate_df.shape[0]\n",
    "cap_valid_rows = capdf.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9d9ad22-4ac7-4c38-9e4f-dc98ab87d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption rows all=17189, valid=15920, invalid=0, duplicate=1269\n"
     ]
    }
   ],
   "source": [
    "print(f'caption rows all={cap_all_rows}, valid={cap_valid_rows}, invalid={cap_invalid_rows}, duplicate={cap_duplicate_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f71a0c3-a841-4000-a750-468e2f1d432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (15920, 13)\n",
      "columns:\n",
      "['relic_id', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(capdf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a9fb109-e0a8-4a56-a240-07771abf9887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 13)\n",
      "columns:\n",
      "['relic_id', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(cap_invalid_df, datadisplay=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6513564d-6ab5-4996-90eb-c1ea593a3937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1269, 13)\n",
      "columns:\n",
      "['relic_id', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(cap_duplicate_df, datadisplay=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b6cbb3f-c798-4ea5-bd7d-28582ae93d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug saving\n",
    "capdf.to_excel(f'./data/capbook-{filename_suffix()}.xlsx', index=False)\n",
    "if cap_invalid_rows:\n",
    "    cap_invalid_df.to_excel(f'./data/capbook-invalid-{filename_suffix()}.xlsx', index=False)\n",
    "if cap_duplicate_rows:    \n",
    "    cap_duplicate_df.to_excel(f'./data/capbook-duplciate-{filename_suffix()}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca659cb4-d462-41e5-8305-d0b08b60d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master file \n",
    "\n",
    "# sheets_all =  ['master']\n",
    "\n",
    "# columns_all:\n",
    "master_columns = [\n",
    "    'check','relic_id_img','relic_id','relic_name','relic_name_eng','relic_common_name','relic_common_name_eng','pattern_usage','pattern_usage_id','pattern_usage_detail','material','source','era','pattern_type','pattern_type_id','pattern_type_detail','pattern_type_detail_eng',\n",
    "    'relic_no','collect','photo_date','photo_eqipment','color','object_img_resolution','pattern_img_resolution','object_file_name','relic_symbol',\n",
    "    '1문단','2문단','3문단','4문단','5문단','6문단','1paragraph','2paragraph','3paragraph','4paragraph','5paragraph','6paragraph'\n",
    "]\n",
    "master_keep_names = [\n",
    "    'check','relic_id_img','relic_name_eng','relic_common_name_eng','pattern_usage_id','pattern_type_id','pattern_type_detail_eng','relic_no','collect','photo_date','photo_eqipment','color','object_img_resolution','pattern_img_resolution','object_file_name','relic_symbol'\n",
    "]\n",
    "master_keep_index = [master_columns.index(cn) for cn in master_keep_names] \n",
    "#print(master_keep_index)\n",
    "\n",
    "master_heads = 4\n",
    "\n",
    "# check skiprows, usecols \n",
    "masdf = pd.read_excel(ofile1, sheet_name='master',  header=None,  skiprows=master_heads, usecols=master_keep_index, names=master_keep_names, na_filter=False, dtype='object', engine='openpyxl',)\n",
    "\n",
    "mas_all_rows = masdf.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf9b8d36-812b-4f4d-ba31-dafbdaec9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace from string columns\n",
    "string_cols = masdf.select_dtypes(include='object').columns\n",
    "masdf[string_cols] = masdf[string_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# remove invalid rows \n",
    "mas_invalid_df = masdf[(masdf['relic_id_img'].isnull()) | (masdf['relic_id_img'].str.len() < 1)]\n",
    "masdf = masdf[(masdf['relic_id_img'].notnull()) & (masdf['relic_id_img'].str.len() > 0)]\n",
    "\n",
    "# remove duplicate rows \n",
    "mas_duplicate_df = masdf[masdf.duplicated(subset=['relic_id_img'])]\n",
    "masdf = masdf.drop_duplicates(subset=['relic_id_img']) \n",
    "\n",
    "mas_invalid_rows = mas_invalid_df.shape[0]\n",
    "mas_duplicate_rows = mas_duplicate_df.shape[0]\n",
    "mas_valid_rows = masdf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56a64ab0-f20e-492a-a586-dd767505e585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master rows all=27054, valid=27054, invalid=0, duplicate=0\n"
     ]
    }
   ],
   "source": [
    "print(f'master rows all={mas_all_rows}, valid={mas_valid_rows}, invalid={mas_invalid_rows}, duplicate={mas_duplicate_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f9f53d4-4fe3-4d16-8ca2-cca06b86d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (27054, 16)\n",
      "columns:\n",
      "['check', 'relic_id_img', 'relic_name_eng', 'relic_common_name_eng', 'pattern_usage_id', 'pattern_type_id', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(masdf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68098858-5de7-4d75-8f53-0893b1528d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 16)\n",
      "columns:\n",
      "['check', 'relic_id_img', 'relic_name_eng', 'relic_common_name_eng', 'pattern_usage_id', 'pattern_type_id', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(mas_invalid_df, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2316b4e-9823-4a46-85e9-ce1c2dd4c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 16)\n",
      "columns:\n",
      "['check', 'relic_id_img', 'relic_name_eng', 'relic_common_name_eng', 'pattern_usage_id', 'pattern_type_id', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(mas_duplicate_df, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dff5c51-f647-4d60-b010-bfee6b706ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug saving\n",
    "masdf.to_excel(f'./data/masbook-{filename_suffix()}.xlsx', index=False)\n",
    "if mas_invalid_rows:\n",
    "    mas_invalid_df.to_excel(f'./data/masbook-invalid-{filename_suffix()}.xlsx', index=False)\n",
    "if mas_duplicate_rows:    \n",
    "    mas_duplicate_df.to_excel(f'./data/masbook-duplicate-{filename_suffix()}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8a3d722-fc20-42b5-a275-bb2b9d7217b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join masdf, metadf, capdf \n",
    "\n",
    "# Find values in masdf['relic_id'] that not metadf['relic_id'] \n",
    "meta_notfound_values = masdf['relic_id_img'][~masdf['relic_id_img'].isin(metadf['relic_id'])]\n",
    "meta_notfound_rows = meta_notfound_values.count()\n",
    "\n",
    "# Find values in masdf['relic_id'] that not metadf['relic_id'] \n",
    "cap_notfound_values = masdf['relic_id_img'][~masdf['relic_id_img'].isin(capdf['relic_id'])]\n",
    "cap_notfound_rows = cap_notfound_values.count()\n",
    "\n",
    "# inner join\n",
    "innerdf = masdf.merge(metadf, how='inner', left_on='relic_id_img', right_on='relic_id', suffixes=['_left1','_right1'], copy=True)  # relic_id added\n",
    "innerdf = innerdf.merge(capdf, how='inner', left_on='relic_id_img', right_on='relic_id', suffixes=['_left2','_right2'], copy=True) # relic_id_left2, relic_id_right2  \n",
    "mas_inner_rows = innerdf.shape[0]\n",
    "\n",
    "# left outer join\n",
    "outerdf = masdf.merge(metadf, how='left', left_on='relic_id_img', right_on='relic_id', suffixes=['_left1','_right1'], copy=True)  # relic_id added\n",
    "outerdf = outerdf.merge(capdf, how='left', left_on='relic_id_img', right_on='relic_id', suffixes=['_left2','_right2'], copy=True) # relic_id_left2, relic_id_right2  \n",
    "mas_outer_rows = outerdf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c76cb22e-a803-4487-86f7-f4dcc2586412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['check', 'relic_id_img', 'relic_name_eng', 'relic_common_name_eng', 'pattern_usage_id', 'pattern_type_id', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol', 'relic_id_left2', 'relic_name', 'relic_common_name', 'pattern_usage', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_detail', 'relic_id_right2', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n",
      "['check', 'relic_id_img', 'relic_id', 'relic_name', 'relic_name_eng', 'relic_common_name', 'relic_common_name_eng', 'pattern_usage', 'pattern_usage_id', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_id', 'pattern_type_detail', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "# delete relic_id_left2, relic_id_right2\n",
    "print(innerdf.columns.tolist())\n",
    "innerdf = innerdf.drop([ 'relic_id_left2','relic_id_right2'], axis=1)\n",
    "# assign relic_id with relic_id_img \n",
    "innerdf['relic_id'] = innerdf['relic_id_img']\n",
    "# reorder columns\n",
    "innerdf = innerdf[master_columns]\n",
    "print(innerdf.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d1cc003-9768-4ca1-b254-eb74834f60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outerdf = outerdf.drop(['relic_id_left2','relic_id_right2'],axis=1)\n",
    "outerdf['relic_id'] = outerdf['relic_id_img']\n",
    "outerdf = outerdf[master_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "414b8435-1f40-4e50-b2da-c90088103a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master inner join rows=14163, outer join rows=27054, meta notfound=128, caption notfound=12888\n"
     ]
    }
   ],
   "source": [
    "print(f'master inner join rows={mas_inner_rows}, outer join rows={mas_outer_rows}, meta notfound={meta_notfound_rows}, caption notfound={cap_notfound_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fbd5229-3aa5-40c2-974c-42cbfffefce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relic_id_img not found at meta count=128\n",
      "relic_id_img not found at meta values:\n",
      "2744     PS0100101200100217800000_A1\n",
      "3303     PS0100101410100566900000_A1\n",
      "3410     PS0100101410101060900000_A1\n",
      "10462                       21248_A1\n",
      "10463                       21249_A1\n",
      "                    ...             \n",
      "26593    PS0100100800100882600000_A3\n",
      "26595    PS0100100800100883000000_A2\n",
      "26596    PS0100100800100883000000_A3\n",
      "26598    PS0100100800100889300000_A2\n",
      "26599    PS0100100800100889300000_A3\n",
      "Name: relic_id_img, Length: 128, dtype: object\n"
     ]
    }
   ],
   "source": [
    "if meta_notfound_rows:\n",
    "    print(f'relic_id_img not found at meta count={meta_notfound_rows}') \n",
    "    print(f'relic_id_img not found at meta values:\\n{meta_notfound_values}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1256af53-e04d-4fcd-91a5-25f2655102db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relic_id_img not found at caption count=12888\n",
      "relic_id_img not found at caption values:\n",
      "2        PS0100200100103812200000_A1\n",
      "5        PS0100200100103812500000_A1\n",
      "6        PS0100200100103812600000_A1\n",
      "7        PS0100200100103812700000_A1\n",
      "10       PS0100200100103971100000_A1\n",
      "                    ...             \n",
      "27049    PS0100308700200317400000_A2\n",
      "27050    PS0100308700200317400000_A3\n",
      "27051    PS0100308700200737600000_A1\n",
      "27052    PS0100308700200737600000_A2\n",
      "27053    PS0100308700200737600000_A3\n",
      "Name: relic_id_img, Length: 12888, dtype: object\n"
     ]
    }
   ],
   "source": [
    "if cap_notfound_rows:\n",
    "    print(f'relic_id_img not found at caption count={cap_notfound_rows}') \n",
    "    print(f'relic_id_img not found at caption values:\\n{cap_notfound_values}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2966f7e1-4aa2-4622-bc8c-c73277020934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (14163, 38)\n",
      "columns:\n",
      "['check', 'relic_id_img', 'relic_id', 'relic_name', 'relic_name_eng', 'relic_common_name', 'relic_common_name_eng', 'pattern_usage', 'pattern_usage_id', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_id', 'pattern_type_detail', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(innerdf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efec9e6f-147b-4fd7-9264-ac149764dd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (27054, 38)\n",
      "columns:\n",
      "['check', 'relic_id_img', 'relic_id', 'relic_name', 'relic_name_eng', 'relic_common_name', 'relic_common_name_eng', 'pattern_usage', 'pattern_usage_id', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_id', 'pattern_type_detail', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph']\n"
     ]
    }
   ],
   "source": [
    "dataframe_info(outerdf, datadisplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "010d845c-7432-4d34-9f26-138c90ee3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debuging\n",
    "if meta_notfound_rows:\n",
    "    with open(f'./data/master_notfound_meta-{filename_suffix()}.txt', 'w') as file:\n",
    "         pprint(meta_notfound_values.tolist(), stream=file)\n",
    "if cap_notfound_rows:\n",
    "    with open(f'./data/master_notfound_caption-{filename_suffix()}.txt', 'w') as file:\n",
    "        pprint(cap_notfound_values.tolist(), stream=file)\n",
    "                \n",
    "innerdf.to_excel(f'./data/innerbook-{filename_suffix()}.xlsx', index=False)\n",
    "outerdf.to_excel(f'./data/outerbook-{filename_suffix()}.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be2dca81-4c09-479f-8455-372ed64195da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to master sheet with outerdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69e7f802-4bbc-4926-9f1e-5cfd752223ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheet=master truncate rows=27054 except header_row_count=4\n"
     ]
    }
   ],
   "source": [
    "# prepare master sheet with header only, trucate datarows \n",
    "masheet = owb1['master']\n",
    "\n",
    "# trucate data\n",
    "truncate_rows_except_headers(masheet, header_row_count=master_heads)\n",
    "\n",
    "# fill master sheet with outerdf \n",
    "for row in outerdf.itertuples(index=False): \n",
    "    masheet.append(row)\n",
    "\n",
    "# set text type and max width \n",
    "text_and_width(masheet, max_width=28) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e64aad6-ecfb-4e5a-b601-7a636478cbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workbook Properties:\n",
      "Modified: 2024-12-13 07:29:36.679685\n",
      "Number of sheets: 1\n",
      "Names of sheets: ['master']\n",
      "\n",
      "Sheet: master\n",
      "  Columns: 38\n",
      "  Rows: 27058\n",
      "  Nonempty rows: 27058\n",
      "  First 5 rows:\n",
      "    (None, None, 'Master', None, None, None, None, 'O', None, None, 'o', None, None, 'o', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)\n",
      "    (None, None, '메타데이터', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '직접촬영만 해당', None, None, None, None, None, None, '한글 캡션', None, None, None, None, None, '영어 캡션', None, None, None, None, None)\n",
      "    ('check', 'relic_id_img', 'RELIC_ID', 'relic_name', 'relic_name_eng', 'relic_common_name', 'relic_common_name_eng', 'pattern_usage', 'pattern_usage_id', 'pattern_usage_detail', 'material', 'source', 'era', 'pattern_type', 'pattern_type_id', 'pattern_type_detail', 'pattern_type_detail_eng', 'relic_no', 'collect', 'photo_date', 'photo_eqipment', 'color', 'object_img_resolution', 'pattern_img_resolution', 'object_file_name', 'relic_symbol', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph')\n",
      "    ('심사', 'Resize 폴더 File List', '고유ID', '원천유물명', '원천유물명(영어)', '일반유물명', '일반유물명(영어)', '용도', '용도ID', '용도 세분류', '재질', '출처', '시대', '문양형태', '형태ID', '형태세분류', '형태세분류(영어)', '유물식별번호', '수집방법', '촬영일', '촬영도구', '색상', '원천A해상도', '원천S해상도', '원천A파일명', '상징', '1문단', '2문단', '3문단', '4문단', '5문단', '6문단', '1paragraph', '2paragraph', '3paragraph', '4paragraph', '5paragraph', '6paragraph')\n",
      "    ('', 'PS0100200100103798900000_A1', 'PS0100200100103798900000_A1', '자물쇠', '', '가구자물쇠', '', '생활소품', '', '생활용품', '금속', '국립민속박물관', '근현대', '동물문', '', '물고기문', '', 'PS037989', '이미지DB', '', '', '흑색', '1080, 1080', '1080, 1080', '', '', '이 자물쇠는 한국전통문화유산으로, 금속으로 제작된 가구 자물쇠이다. 전통 가구에 쓰이며 문이나 서랍을 안전하게 잠그는 용도로 활용된다. 내구성 있는 구조와 섬세한 디자인으로 인해 실용성과 미적 가치를 동시에 갖추고 있다.', '믈고기 문양이 새겨진 이 가구 자물쇠에는 자물쇠의 외각에 배치되어 생동감을 준다.. 물고기 문양은 다산과 풍요를 상징하며 가구 사용자에게 행운과 번영을 기원하는 역할을 한다.', '한국전통문양인 물고기문은 물고기의 형태를 바탕으로 구성되어 있다. 물고기 문양은 세밀하게 표현되며, 물고기의 비늘 등 세부적인 부분이 정교하게 새겨져 있어 생동감과 깊이를 더한다.', '문양의 주된 색상은 금속 본연의 색이 강조되었으며, 재질은 금속이다. 물고기문양은 한국전통문화유산에서 번영과 다산을 상징한다. 물고기는 다양한 자연환경에서 살아남는 특성으로 인해 강인함과 적응력을 나타내며, 이러한 특징이 풍요와 다산으로 연결된다.', '가구자물쇠는 전통적인 디자인과 실용적인 기능을 통해 한국의 생활 문화와 깊은 연결을 갖는다. 이 자물쇠는 단순한 도구 이상의 의미를 지니며, 물고기문양이 더해져 다산과 번영을 기원하는 한국전통문화유산으로 자리 잡고 있다. 금속 재질로 제작되어 내구성이 뛰어나며, 전통 가구에 유용하게 사용된다.', '‘한국전통문화유산’, ‘한국전통문양’, 자물쇠, ‘동물문’, ‘물고기문’, 풍요, 다산', 'This lock is a part of the Korean traditional cultural heritage, specifically a metal furniture lock. It is commonly used in traditional furniture to securely lock doors or drawers. It offers both practical and aesthetic value, thanks to its durable structure and delicate design.', 'The furniture lock features fish patterns, adding a visual characteristic to its design. These patterns, placed around the exterior of the lock, symbolize abundance and prosperity, serving to wish luck and prosperity upon the user.', 'The Korean traditional fish pattern is based on the form of a fish with intricate detailing. The scales and other fine features of the fish are intricately carved, adding vibrancy and depth to the design.', 'The main color of the pattern highlights the natural color of metal, and its material is metal. In Korean traditional cultural heritage, the fish pattern symbolizes prosperity and abundance. Fish are known for their resilience in various natural environments, representing strength and adaptability, which are linked to prosperity and abundance.', 'The furniture lock is deeply connected to Korean lifestyle and culture through its traditional design and practical function. More than a simple tool, it embodies the significance of wishing for abundance and prosperity, reinforced by the fish pattern. Made of metal, it is notably durable and serves a functional role in traditional furniture.', '‘Korean Traditional Cultural Heritage’, ‘Korean Traditional Pattern’, lock, ‘Animal Pattern’, ‘Fish Pattern’, prosperity, abundance')\n",
      "  Tail 5 rows:\n",
      "    ('', 'PS0100308700200317400000_A1', 'PS0100308700200317400000_A1', '연화보상화문 수막새', '', '수막새', '', '건축물', '', '수막새', '토제', '울산박물관', '통일신라', '식물문', '', '연화보상화문, 보상화문, 연꽃문, 연주문', '', 'PS003174', '이미지DB', '', '', '다자색', '1057, 1080', '1057, 1080', '', '', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan)\n",
      "    ('', 'PS0100308700200317400000_A2', 'PS0100308700200317400000_A2', '연화보상화문 수막새', '', '수막새', '', '건축물', '', '', '토제', '울산박물관', '통일신라', '식물문', '', '', '', 'PS003174', '이미지DB', '', '', '다자색', '1057, 1080', '1057, 1080', '', '', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan)\n",
      "    ('', 'PS0100308700200317400000_A3', 'PS0100308700200317400000_A3', '연화보상화문 수막새', '', '수막새', '', '건축물', '', '', '토제', '울산박물관', '통일신라', '인공물문', '', '', '', 'PS003174', '이미지DB', '', '', '회색', '1057, 1080', '1057, 1080', '', '', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan)\n",
      "    ('', 'PS0100308700200737600000_A1', 'PS0100308700200737600000_A1', '연화문 수막새', '', '수막새', '', '건축물', '', '수막새', '토제', '울산박물관', '통일신라', '식물문', '', '연꽃문, 연주문', '', 'PS007376', '이미지DB', '', '', '구색', '1080, 1048', '1080, 1048', '', '', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan)\n",
      "    ('', 'PS0100308700200737600000_A2', 'PS0100308700200737600000_A2', '연화문 수막새', '', '수막새', '', '건축물', '', '', '토제', '울산박물관', '통일신라', '식물문', '', '', '', 'PS007376', '이미지DB', '', '', '회색', '1080, 1048', '1080, 1048', '', '', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan)\n",
      "    ('', 'PS0100308700200737600000_A3', 'PS0100308700200737600000_A3', '연화문 수막새', '', '수막새', '', '건축물', '', '', '토제', '울산박물관', '통일신라', '인공물문', '', '', '', 'PS007376', '이미지DB', '', '', '자황색', '1080, 1048', '1080, 1048', '', '', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan)\n"
     ]
    }
   ],
   "source": [
    "workbook_info(owb1, datadisplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d95f9a64-e7c7-4819-a51f-9a75a3ae4185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result file=./data/master-14868-163302.xlsx\n"
     ]
    }
   ],
   "source": [
    "# master saving\n",
    "filename = f'./data/master-{filename_suffix()}.xlsx'\n",
    "owb1.save(filename) \n",
    "print(f'result file={filename}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fe38f94-66ac-42bc-84f3-c65eae4e74ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, eplapsed seconds = 249.73599982261658\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Done, eplapsed seconds = {end_time - start_time}\")\n",
    "\n",
    "# copy file to \\\\BlueServer\\임시폴더\\이남구임시파일\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e548c-591b-4e23-ac12-1310fa639552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
